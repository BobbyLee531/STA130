{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80b9295",
   "metadata": {},
   "source": [
    "\n",
    "### Chatbot link:https://chatgpt.com/share/f6a2bd98-f4c7-477d-a47b-05b7abf857d0\n",
    "\n",
    "## 1. Dataset Overview\n",
    "- I downloaded a housing dataset from: \n",
    "  `https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv`.\n",
    "- The dataset was analyzed for columns and rows using Python, resulting in the following:\n",
    "  - **Columns**: 10 columns (`longitude`, `latitude`, `housing_median_age`, `total_rooms`, `total_bedrooms`, `population`, `households`, `median_income`, `median_house_value`, `ocean_proximity`).\n",
    "  - **Rows**: 20,640 rows (observations).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f5ac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640,\n",
       " Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "        'total_bedrooms', 'population', 'households', 'median_income',\n",
       "        'median_house_value', 'ocean_proximity'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "housing_data = pd.read_csv(url)\n",
    "\n",
    "columns = housing_data.columns\n",
    "row_count = len(housing_data)\n",
    "\n",
    "row_count, columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c76c7",
   "metadata": {},
   "source": [
    "## 2. Explanation of Terms\n",
    "- **Observations**:\n",
    "  - Definition: Each row of data represents an observation.\n",
    "  - In this dataset: Each observation represents one housing information at a certain location.\n",
    "- **Variables**:\n",
    "  - Definition: Each column is a variable, representing a different characteristic.\n",
    "  - In this dataset: There are 10 variables in total.\n",
    "- **In my own words**\n",
    "  - Let say this data set is a 2D array dt[x][y], so that a observation is one entire row, like dt[1], and a variable is one idividaul element in the array, such as dt[1][2].\n",
    "\n",
    "## 3. Summary of Dataset Columns\n",
    "- Using `.describe()`:\n",
    "  - **Numerical variables**: Summary statistics such as mean, median, standard deviation, min, and max.\n",
    "  - **Categorical variable (`ocean_proximity`)**: Counts for each category like `<1H OCEAN`, `INLAND`, etc.\n",
    "- Using `.value_counts()`:\n",
    "    This will generate a summary for a specific column. It will tell you the amount of each value in that column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52d1e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count   20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "unique           NaN           NaN                 NaN           NaN   \n",
      "top              NaN           NaN                 NaN           NaN   \n",
      "freq             NaN           NaN                 NaN           NaN   \n",
      "mean     -119.569704     35.631861           28.639486   2635.763081   \n",
      "std         2.003532      2.135952           12.585558   2181.615252   \n",
      "min      -124.350000     32.540000            1.000000      2.000000   \n",
      "25%      -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%      -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%      -118.010000     37.710000           37.000000   3148.000000   \n",
      "max      -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "        total_bedrooms    population    households  median_income  \\\n",
      "count     20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "unique             NaN           NaN           NaN            NaN   \n",
      "top                NaN           NaN           NaN            NaN   \n",
      "freq               NaN           NaN           NaN            NaN   \n",
      "mean        537.870553   1425.476744    499.539680       3.870671   \n",
      "std         421.385070   1132.462122    382.329753       1.899822   \n",
      "min           1.000000      3.000000      1.000000       0.499900   \n",
      "25%         296.000000    787.000000    280.000000       2.563400   \n",
      "50%         435.000000   1166.000000    409.000000       3.534800   \n",
      "75%         647.000000   1725.000000    605.000000       4.743250   \n",
      "max        6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "        median_house_value ocean_proximity  \n",
      "count         20640.000000           20640  \n",
      "unique                 NaN               5  \n",
      "top                    NaN       <1H OCEAN  \n",
      "freq                   NaN            9136  \n",
      "mean         206855.816909             NaN  \n",
      "std          115395.615874             NaN  \n",
      "min           14999.000000             NaN  \n",
      "25%          119600.000000             NaN  \n",
      "50%          179700.000000             NaN  \n",
      "75%          264725.000000             NaN  \n",
      "max          500001.000000             NaN  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_rooms\n",
       "1527.0     18\n",
       "1613.0     17\n",
       "1582.0     17\n",
       "2127.0     16\n",
       "1717.0     15\n",
       "           ..\n",
       "9614.0      1\n",
       "10839.0     1\n",
       "11872.0     1\n",
       "6205.0      1\n",
       "10035.0     1\n",
       "Name: count, Length: 5926, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_summary = housing_data.describe(include='all')\n",
    "\n",
    "print(full_summary)\n",
    "\n",
    "housing_data['total_rooms'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5017ec1",
   "metadata": {},
   "source": [
    "## 4. Discrepancies Between `.shape` and `.describe()`\n",
    "- **Number of Columns Analyzed**:\n",
    "  - `.shape` gives the total number of rows and columns.\n",
    "  - `.describe()` analyzes only numerical columns by default but can include categorical data using `include='all'`.\n",
    "  \n",
    "- **\"Count\" in `.describe()`**:\n",
    "  - Reflects the number of non-null entries in each column, not the total number of rows.\n",
    "  - If a column has empty cells, the count from `.describe()` will be less than the total rows.\n",
    "\n",
    "- comparing `.shape` to `.describe()`, .`.shape` won't ignore the empty cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10532020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = housing_data.shape\n",
    "\n",
    "shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d742aeb",
   "metadata": {},
   "source": [
    "## 5. Explanation of `.shape` (Attribute) vs. `.describe()` (Method)\n",
    "- **`.shape`**:\n",
    "  - Attribute \n",
    "  - Returns a tuple (amount of rows, amount of columns).\n",
    "  - Does not require parentheses ().\n",
    "  - Example: housing_data.shape return (20640, 10).\n",
    "  \n",
    "- **`.describe()`**:\n",
    "  - Method \n",
    "  - Provides a statistical summary of the data.\n",
    "  - Requires parentheses because it's a function.\n",
    "  - Returns information like mean, median, and count for each column.\n",
    "  - Example: housing_data.describe() returns summary statistics like mean, median, and count for each column.\n",
    "\n",
    "\n",
    "- Attributes do not require parentheses as they represent stored properties of an object.\n",
    "- Methods require parentheses, and could modify the object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc3e87",
   "metadata": {},
   "source": [
    "## 6. Info that .describe provide, link:https://chatgpt.com/share/ce14f3ae-168a-4998-9171-4cbd18e875c8\n",
    "- **count**: The number of non-null (valid) entries in the column.\n",
    "- **mean**: The average value of the data in the column.\n",
    "- **std**: The standard deviation, which measures the dispersion of the data from the mean.\n",
    "- **min**: The minimum value in the data column.\n",
    "- **25%**: The first quartile (Q1), or the 25th percentile.\n",
    "- **50%**: The median (second quartile, Q2), or the 50th percentile.\n",
    "- **75%**: The third quartile (Q3), or the 75th percentile.\n",
    "- **max**: The maximum value in the data column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f9dfa9",
   "metadata": {},
   "source": [
    "## 7. Compare and use .dropna() and del df['col']\n",
    "- **dropna**: When there's only a few rows was missing elements in their cells, using dropna will get rid of those rows. Because there's only a few rows, using dropna won't really affect the analysis.\n",
    "- **del**: when there's a certain column, which contains a significant amount of empty cells, use del df['col] to delete this whole column beacause keeping that column won't provide us much value.\n",
    "- **Why use del before dropna**: It prevents the algorithm from unnecessarily dropping rows that might only be missing data in the column that will be deleted anyway. This way, when the column with a lot of missing values is removed first, the subsequent df.dropna() can operate more efficiently, focusing only on the remaining columns with meaningful data.\n",
    "\n",
    "**example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b32e971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       List Price  Amazon Price    NumPages     Pub year      Height  \\\n",
      "count  324.000000    325.000000  323.000000   324.000000  321.000000   \n",
      "mean    18.579753     13.333846  335.857585  2002.206790    8.163240   \n",
      "std     14.252829     13.727679  161.984389    10.629002    0.918739   \n",
      "min      1.500000      0.770000   24.000000  1936.000000    5.100000   \n",
      "25%     13.950000      8.600000  208.000000  1998.000000    7.900000   \n",
      "50%     15.000000     10.200000  320.000000  2005.000000    8.100000   \n",
      "75%     19.950000     13.130000  416.000000  2010.000000    8.500000   \n",
      "max    139.950000    139.950000  896.000000  2011.000000   12.100000   \n",
      "\n",
      "            Width       Thick   Weight_oz  \n",
      "count  320.000000  324.000000  316.000000  \n",
      "mean     5.585000    0.907716   12.487975  \n",
      "std      0.874057    0.368625    6.644648  \n",
      "min      4.100000    0.100000    1.200000  \n",
      "25%      5.200000    0.600000    7.800000  \n",
      "50%      5.400000    0.900000   11.200000  \n",
      "75%      5.900000    1.100000   16.000000  \n",
      "max      9.500000    2.100000   35.200000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Title            0\n",
       "Author           1\n",
       "List Price       1\n",
       "Amazon Price     0\n",
       "Hard_or_Paper    0\n",
       "NumPages         2\n",
       "Publisher        1\n",
       "Pub year         1\n",
       "ISBN-10          0\n",
       "Height           4\n",
       "Width            5\n",
       "Thick            1\n",
       "Weight_oz        9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "\n",
    "ab = pd.read_csv(url, encoding='latin1')\n",
    "\n",
    "print(ab.describe())\n",
    "\n",
    "missing_values_amazon_books_before = ab.isnull().sum()\n",
    "\n",
    "missing_values_amazon_books_before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81c856",
   "metadata": {},
   "source": [
    "**Before using del and dropna, we can see that there are 9 empty cells missing in the column of \"Weight_oz\". Comparing to the other columns, this is a lot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "950eaf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       List Price  Amazon Price    NumPages     Pub year      Height  \\\n",
      "count  324.000000    325.000000  323.000000   324.000000  321.000000   \n",
      "mean    18.579753     13.333846  335.857585  2002.206790    8.163240   \n",
      "std     14.252829     13.727679  161.984389    10.629002    0.918739   \n",
      "min      1.500000      0.770000   24.000000  1936.000000    5.100000   \n",
      "25%     13.950000      8.600000  208.000000  1998.000000    7.900000   \n",
      "50%     15.000000     10.200000  320.000000  2005.000000    8.100000   \n",
      "75%     19.950000     13.130000  416.000000  2010.000000    8.500000   \n",
      "max    139.950000    139.950000  896.000000  2011.000000   12.100000   \n",
      "\n",
      "            Width       Thick  \n",
      "count  320.000000  324.000000  \n",
      "mean     5.585000    0.907716  \n",
      "std      0.874057    0.368625  \n",
      "min      4.100000    0.100000  \n",
      "25%      5.200000    0.600000  \n",
      "50%      5.400000    0.900000  \n",
      "75%      5.900000    1.100000  \n",
      "max      9.500000    2.100000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Title            0\n",
       "Author           0\n",
       "List Price       0\n",
       "Amazon Price     0\n",
       "Hard_or_Paper    0\n",
       "NumPages         0\n",
       "Publisher        0\n",
       "Pub year         0\n",
       "ISBN-10          0\n",
       "Height           0\n",
       "Width            0\n",
       "Thick            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "\n",
    "ab = pd.read_csv(url, encoding='latin1')\n",
    "\n",
    "del ab['Weight_oz']\n",
    "\n",
    "amazon_books_cleaned = ab.dropna()\n",
    "\n",
    "print(ab.describe())\n",
    "\n",
    "missing_values_amazon_books_after = amazon_books_cleaned.isnull().sum()\n",
    "\n",
    "missing_values_amazon_books_after\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b9ace",
   "metadata": {},
   "source": [
    "After cleaning the dataset by removing the Weight_oz column and applying dropna() to remove any rows with missing data. I can now review the null count in the dataset to see the impact of the cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061d1de",
   "metadata": {},
   "source": [
    "## 8. link: https://chatgpt.com/share/44d48adb-a919-43dd-9646-908a83dfc5a1\n",
    "- 1. Use of 'df.groupby(\"col1\")[\"col2\"].describe()'\n",
    "     By using the method of groupby before .describe(), it will first sort the data set by col1 and then analyze the data in col2 based on the rules of .describe()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26294df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "        count       mean        std  min       25%      50%   75%       max\n",
      "pclass                                                                     \n",
      "1       216.0  84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292\n",
      "2       184.0  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000\n",
      "3       491.0  13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "grouped_description = df.groupby(\"pclass\")[\"fare\"].describe()\n",
    "\n",
    "print(grouped_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f32111b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6404461",
   "metadata": {},
   "source": [
    "- **2**. When using  'df.groupby(\"col1\")[\"col2\"].describe()', count will show us the count for each individual catogory, which belongs to \"col1\". However, count in df.describe will just count how many cell in each row is not empty. From the .groupby().describe(), we can tell that the mean price of each class increases as from 3 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14d131",
   "metadata": {},
   "source": [
    "- **3**. error correction(chatgpt shows an error when trying to get a sharable link,the following doc is the summary https://docs.google.com/document/d/1NPraWJf5l8xX-MyJLAoaqhkQiL2kt8H7hBBjnWxqjac/edit?usp=sharing): \n",
    "    - A. Forget to include import pandas as pd in code\n",
    "        - chatgpt:\"The error you're encountering is due to the fact that the pandas library (pd) is not imported in your code. You need to import the pandas library before using it.\"\n",
    "            It found the mistake\n",
    "            \"import pandas as pd\"\n",
    "            provided me a possible fix that could be applied\n",
    "            \"Make sure you have pandas installed in your environment by running pip install pandas if needed.\"\n",
    "            with some extention.\n",
    "        - google: I need to look for the proper solution from all those tabs that Google provides me. The mistake got fixed after looking through two or three possible solutions.\n",
    "    - B. Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "        - chatgpt: \"It looks like you're encountering an issue because of a typo in the URL. The file name should be titanic.csv, not titanics.csv.\"\n",
    "            it directly point out that there might be a typo.\n",
    "        - google: By just googling the error message\"HTTPError: HTTP Error 404: Not Found\", it won't give any valuable response. But we are able to know that the URL might be wrong because it's an HTTPError.\n",
    "    - C. Try to use a dataframe before it's been assigned into the variable\n",
    "        - chatgpt: \"Define the variable df (or DF, but be consistent) before you use it.\n",
    "            Use the correct variable name (lowercase df, since it’s the convention).\"\n",
    "        - google: It won't provide you with the solution for this exact error, but I can still find the words like \"define you variable before using it.\"\n",
    "    - D. Forget one of the parentheses somewhere the code\n",
    "        - chatgpt:\"The issue you're facing is due to a missing closing parenthesis in the print(df.head() statement. You need to close it with ).\"\n",
    "        - google: able to point out that there is a ')' missing.\n",
    "        - This one is straight foward, could just be fixed base on the error message \"SyntaxError: '(' was never closed\"\n",
    "    - E. Mistype one of the names of the chained functions with the code\n",
    "        - chatgpt: \"The error is due to a typo in the code. You wrote describel() instead of describe().\" It points out the typo and shows me how to fix it.\n",
    "        - google: \n",
    "        - This one is also straight foward, could just be fixed base on the error message \"AttributeError: 'SeriesGroupBy' object has no attribute 'describel'\"\n",
    "    - F. Use a column name that's not in your data for the groupby and column selection\n",
    "        - chatgpt:\"The error is caused by a typo in your column name. You wrote \"ppclass\" instead of \"pclass\". The correct column name is \"pclass\".\" It tells me that I might indicate to another column.\n",
    "        - google: It cannot show me the way of fixing this exact situation, but I'm able to fix it from the error message\"KeyError: 'ppclass'\".\n",
    "    - G. Forget to put the column name as a string in quotes for the groupby and column selection\n",
    "        - chatgpt: \"The issue you're encountering is due to referencing the column fare without quotes.\"\n",
    "        - google: It cannot show me the way of fixing this exact situation, but I'm able to fix it from the error message\"NameError: name 'fare' is not defined\".\n",
    "     \n",
    "     \n",
    "     **Overall, with chatbot I can tell me the error and how to correct it directly and accurately, but I can't find the exact same thing with Google.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2fe6fd",
   "metadata": {},
   "source": [
    "## 9. Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e8341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
